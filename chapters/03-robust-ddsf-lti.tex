\chapter{Robust Data-Driven Safety Filter}\label{chap:robust-ddsf-lti}

In this chapter, we will discuss and compare different formulations of robust data-driven safety filters for LTI system with bounded output noise.
We will first introduce the direct formulation of the robust data-driven safety filter with rigorous constraint tightening scheme, and illustrate its limitations using a single-input-single-output (SISO) LTI system.
Then we will introduce the indirect formulation with qualitative constraint tightening scheme, and show that it can overcome the limitations of the direct formulation.

Before detailing the robust data-driven safety filters, we first introduce the system we will be working with: LTI system with bounded output noise.
It is an LTI system with additive output noise, as defined in \cref{def:lti-system,def:output-noise}.
In addition, we assume the output noise is bounded, as defined in \cref{def:bounded-output-noise}.

\begin{definition}[Bounded output noise]\label{def:bounded-output-noise}
    As for the noise $\varepsilon_t$ defined in \cref{def:output-noise}, we say it's bounded if there exists a bounded set $\Epset \subseteq \RealVec{p}$, which makes $\varepsilon_t \in \Epset$ for all $t$.
\end{definition}

\begin{remark}\label{remark:state-noise-lti}
    Although we do not explicitly deal with process noise in this chapter, we can also incorporate this kind of noise when the system is \emph{asymptotically stable} and the noise is bounded.
    This is because, when an LTI system is asymptotically stable, the \emph{Bounded Input Bounded Output (BIBO)} stability holds \cite{antsaklisStability2006}.
    Then bounded state noise can be viewed as bounded additional input to the system, and will result in bounded output noise with additional structure.
\end{remark}

To simplify the discussion, we use hyper-box shaped output constraint, and similarly use infinity norm to represent the bound of noise.
More general case can be discussed similarly, with much more complicated notation.

\begin{assumption}\label{asm:hyperbox-output-constraint}
    The output constraint set $\Yset$ is a hyper-box, that is: $\Yset = \left\{y | \infnorm{y} \leq \ymax \right\}$.
\end{assumption}

\begin{assumption}\label{asm:infty-norm-noise}
    The noise bound $\barvareps$ is defined as: $\barvareps = \max_{\varepsilon \in \Epset} \infnorm{\varepsilon}$.
    Or equivalently, we put bound on the output noise: $\infnorm{\varepsilon_t} \leq \barvareps$ for all $t$.    
\end{assumption}

\section{Direct Formulation}\label{sec:direct-formulation}

As has been discussed in \cite{coulsonDataenabledPredictiveControl2019}, when the dataset output sequence $\datasetSequence{\tildey}{N}$ is noisy, the Hankel matrix $\hankel{L+n}{\tildey^d}$ will almost surely become full rank, which means the column space of $\hankel{L+n}{\tildey^d}$ will be $\Real^{m(L+n)}$.
In another word, the original data driven safety filter formulation \cref{eq:nominal-ddsf} will be able to make \emph{any prediction} possible.

As can be seen in \cref{eq:nominal-ddsf-initial,eq:nominal-ddsf-dynamics}, the noise will affect the prediction in two ways: the initial condition and the noisy dataset.
To overcome this problem, it is advised in \cite{coulsonDataenabledPredictiveControl2019} to add a regularizer into the objective function, and add a slack variable to compensate for the effect of noise.
Detailed discussion follows after the formulation.

Also, as in common MPC schemes, it is also necessary to modify the constraint to deal with the noise.
We incorporate the constraint tightening scheme proposed and analysed in \cite{berberichRobustConstraintSatisfaction2020}.

The final point mention here is, we will consider the n-step receding horizon scheme, in contrast to the one-step receding horizon scheme used for nominal data-driven safety filter introduced in \cref{chap:nominal-ddsf}. 
This is needed because of the terminal constraint, which will be clear in the proof \cref{apps:prf-roubust-direct}.

With all these modifications, the direct robust data-driven safety filter can be formulated as: 

\begin{subequations}
\label{eq:robust-ddsf-direct}
\begin{align}
    \min_{\substack{\alpha, \sigma \\ \baru, \bary}} \quad & \norm{\subseq{\baru}{0}{n-1} - \uObjn(t)}_{\subseq{R}{0}{n-1}}^2 + \lamalpha \bar{\varepsilon} \norm{\alpha}_2^2 + \lamsigma \norm{\sigma}_2^2 \label{eq:robust-ddsf-direct-cost}\\
    \textrm{s.t.} \quad & 
    \begin{bmatrix}
        \subseq{\baru}{-n}{L-1} \\
        \subseq{\bary}{-n}{L-1} + \sigma \\
    \end{bmatrix} = 
    \begin{bmatrix}
        \hankel{L+n}{u^d} \\
        \hankel{L+n}{\tildey^d} \\
    \end{bmatrix} \alpha \label{eq:robust-ddsf-direct-dynamic}\\
    & 
    \begin{bmatrix}
        \subseq{\baru}{-n}{-1} \\
        \subseq{\bary}{-n}{-1} \\
    \end{bmatrix} = 
    \begin{bmatrix}
        \subseq{u}{t-n}{t-1} \\
        \subseq{\tildey}{t-n}{t-1} \\
    \end{bmatrix} \label{eq:robust-ddsf-direct-initial}\\
    & 
    \begin{bmatrix}
        \subseq{\baru}{L-n}{L-1} \\
        \subseq{\bary}{L-n}{L-1} \\
    \end{bmatrix} = 
    \begin{bmatrix}
        \vRepeatVec{\us}{n} \\
        \vRepeatVec{\ys}{n} \\
    \end{bmatrix} \label{eq:robust-ddsf-direct-terminal}\\
    &
    \baru_k \in \Uset, \quad k \in \listinI{0}{L-1} \label{eq:robust-ddsf-direct-input}\\
    &
    \infnorm{\bary_k} + a_{1,k}\norm{\baru}_1 + a_{2,k}\norm{\alpha}_1 \nonumber \\
    &
    \quad + a_{3,k}\norm{\sigma}_1 + a_{4,k} \leq y_{\max}, \quad k \in \listinI{0}{L-1} \label{eq:robust-ddsf-direct-output} \\
    &
    \norm{\sigma}_\infty \leq \bar{\varepsilon}\left( \norm{\alpha}_1 + 1 \right) \textperiod \label{eq:robust-ddsf-direct-sigma}
\end{align}
\end{subequations}
where $\sigma$ is a slack variable introduced to deal with noise in dataset and online observation, $\lamalpha$ and $\lamsigma$ are two regularizing weights, $\subseq{\uObj}{0}{n-1}$ are $n$ objective inputs given by the arbitrary controller, $\subseq{R}{0}{n-1}$ represents the block-diagonal matrix with $n$ weighting matrices $R_0$ to $R_{n-1}$ on the diagonal, $\tildey^d$ is the noisy dataset output sequence, $a_{1,k}$ to $a_{4,k}$ are constraint tightening constants introduced in \cite{berberichRobustConstraintSatisfaction2020}.

We are using the n-step receding horizon scheme, which means the first $n$ inputs of the optimal solution will be applied to the system.
As a result, we need $n$ objective inputs from the learning-based controller.

As stated before, we need to add slack variable $\sigma$ to compensate for the effect of prediction error, which is introduced by the noise in dataset and online observation.
Constraint \cref{eq:robust-ddsf-direct-sigma} is an auxiliary constraint to render an upper-bound on $\sigma$.
Since the purpose of $\sigma$ is to compensate for the effect of noise, and the noise comes into the prediction both by initial condition and the noisy dataset, it should have an upper bound related to $\barvareps$ and variable $\alpha$, as can be reflected in \cref{eq:robust-ddsf-direct-sigma}.
% Also, since the noise originate from the dataset is amplified by $\alpha$, this upper bound should also be related to $\alpha$.
It is worth-noticing that, constraint \cref{eq:robust-ddsf-direct-sigma} is not convex.
As stated in \cite{berberichDataDrivenRobust2021}, in practice it can be omitted, since it will be satisfied automatically with proper choice of regularizing constants $\lamalpha$ and $\lamsigma$.
Also, in order to retain closed-loop guarantees, it is enough to replace the constraint with a convex relaxation of the form $\infnorm{\sigma} \leq C \barvareps$, where $C$ is a large enough constant.
For $\sigma$ this regularizing constant is not affected by $\barvareps$, since this regularizing effect should still exist even if the noise bound is zero.
In practice, $\sigma$ should be kept near zero by choosing $\lamsigma$ and $\lamalpha$ properly.

Since the noise also affect the prediction by noisy dataset, which will be reflected in the dynamic constraint \cref{eq:robust-ddsf-direct-dynamic}, we need to add a regularizer term $\lamalpha \barvareps \twonorm{\alpha}^2$.
This term will penalize on larger $\alpha$, which will result in larger prediction error since the noise in dataset is amplified by $\alpha$.
We add $\barvareps$ into the regularizer for $\alpha$ by the intuition that, the regularizing effect on $\alpha$ should be smaller given a smaller noise bound.
As an extreme case, if $\barvareps = 0$, the regularizer will vanish.

As mentioned in \cref{sec:motivation-and-background}, there exists numerous choices of regularizers for $\alpha$ and $\sigma$ \cite{mattssonRegularizationDeePC,dorflerBridgingDirectIndirect2023}.
To provide qualitative guarantees of recursive feasibility and closed-loop constraint satisfaction, we choose the 2-norm regularizer for $\alpha$ and $\sigma$.
We conjecture that the guarantees can also be provided for other choices of regularizers such as 1-norm or general quadratic norm of the form $\norm{\alpha}_R$, but we leave this for future work.
Another interesting direction of work would be to investigate the effect of different choices of regularizers on the closed-loop performance.

The constraint tightening constants $a_{1,k}$ to $a_{4,k}$ are introduced in \cite{berberichRobustConstraintSatisfaction2020}, which can provide rigorous guarantees for the closed-loop constraint satisfaction.

Because of the n-step receding horizon scheme and terminal constraint \cref{eq:robust-ddsf-direct-terminal}, the prediction horizon needs to be longer than $2n$.

\begin{assumption}\label{asm:horizon-2-n}
    The prediction horizon $L$ satisfies $L \geq 2n$.
\end{assumption}

For the qualitative guarantees, we also need an upper-bound on the deviation from objective input.

\begin{assumption}\label{asm:objective-input-bound}
    The maximum deviation from objective input is bounded, that is:
    \begin{align*}
        \norm{\subseq{\baru}{0}{n-1} - \subseq{\uObj}{0}{n-1}}_{\subseq{R}{0}{n-1}} \leq \barD \textperiod
    \end{align*}
    for some positive constant $\barD$, any feasible input sequence candidate $\subseq{\baru}{0}{n-1}$ and objective inputs $\subseq{\uObj}{0}{n-1}$ for all time steps.
\end{assumption}

Note that \cref{asm:objective-input-bound} can be satisfied in practice, since the input constraint $\Uset$ is usually known and bounded, and we can always first project the objective input to the input constraint set $\Uset$.

We further need the assumption that the equilibrium point $\us$ and $\ys$ are in the interior of the input and output constraint set $\Uset$ and $\Yset$.

\begin{assumption}\label{asm:equilibrium-interior}
    The equilibrium point $\us$ and $\ys$ are in the interior of the input and output constraint set $\Uset$ and $\Yset$.
\end{assumption}

We can prove that the formulation \cref{eq:robust-ddsf-direct} can provide qualitative guarantees of recursive feasibility and closed-loop constraint satisfaction.

\begin{theorem}[Qualitative guarantees for direct formulation]\label{thm:robust-ddsf-direct}
    Consider a controllable LTI system with bounded output noise, along with n-step receding horizon scheme.
    And suppose \cref{asm:dataset-L-2n-rich,asm:horizon-2-n,asm:objective-input-bound,asm:equilibrium-interior} are satisfied.
    With proper choice of regularizing constants $\lamalpha$ and $\lamsigma$, there exist a constant $\varepsmax$ and a cost bound $\barV$, that make following statements true:
    when $\barvareps \leq \varepsmax$, and the optimal cost at time step $t_0$ is no larger than $\barV$, recursive feasibility and closed-loop constraint satisfaction can be guaranteed after $t_0$ with the formulation \cref{eq:robust-ddsf-direct} and the optimal cost for all time steps $t \geq t_0$ will be no larger than $\barV$.
\end{theorem}

Note that in addition to recursive feasibility and closed-loop constraint satisfaction, we also specify a recursive upperbound on the optimal cost.
This is needed to ensure the guarantees are indeed recursive, namely can be ensured for all time steps after $t_0$.
We leave the proof of \cref{thm:robust-ddsf-direct} to \cref{apps:prf-roubust-direct}.

This guarantee is called \emph{qualitative}, since it does not provide any quantitative information about the choice of regularizing constants $\lamalpha$ and $\lamsigma$, maximum noise bound $\varepsmax$ and cost bound $\barV$.
We refer to \cref{apps:prf-roubust-direct} for a more detailed discussion.
In practice, $\lamalpha$ and $\lamsigma$ are two hyperparameters that can be chosen by trial and error.

\subsection{Numerical Example for Direct Formulation}\label{subsec:numerical-example-direct}

In this section, we provide a numerical example to illustrate the limitations of the direct formulation \cref{eq:robust-ddsf-direct}.
To simplify the illustration, we choose an SISO system, which is the same as the one used in \cite{berberichRobustConstraintSatisfaction2020}, with transfer function:

\begin{equation*}
    G(z) = 0.01\frac{2z^2 + 6.1z + 1}{z^3 - 2.1z^2 + 1.5z - 0.3} \textperiod
\end{equation*}

equipped with constraint sets $\Uset = \Yset = \left[-10, 10\right]$.
This is an LTI system with $m=p=1$ and $n=l=3$.

We choose a very small noise bound $\barvareps = 0.0001$, with regularizing constants $\barvareps\lamalpha = 500$ and $\lamsigma = 500$.
The output noise for each time step, both in dataset trajectory and online observation, is sampled uniformly from $\left[-\barvareps, \barvareps\right]$.
The reason for this small noise bound will be clear later.

The dataset trajectory is of length $2000$, generated by sampling input uniformly random from $\Uset$ at each time step, and starting from the initial state $x_0 = \transpose{\begin{bmatrix}0 & 0 & 0\end{bmatrix}}$.
The prediction horizon is $L=20$, and we set the equilibrium point to be $\us = \ys = 0$.

By applying an open-loop objective control input of a sine wave with amplitude $15$, we observe the closed-loop input and output as shown in \cref{fig:robust-direct-conservative}.

\includefig{robust-direct-conservative.pdf}{0.98}{Closed-loop input and output with direct method and unsafe objective input.}{fig:robust-direct-conservative}

As can be seen from \cref{fig:robust-direct-conservative}, the closed-loop input and output are far from the constraint limit.
This is due to the very conservative constraint tightening scheme introduced in \cite{berberichRobustConstraintSatisfaction2020}, based on a generous estimation of bound of prediction error.

Note that the constraint tightening constants $a_{1,k}$ to $a_{4,k}$ depend on the dataset trajectory, the system constants and the noise bound $\barvareps$.
To illustrate the conservative nature of this constraint tightening scheme, we list the value of $a_{4, 19}$ with different noise bound in \cref{tab:robust-direct-tightening}.

{\renewcommand{\arraystretch}{1.3}%
\begin{center}
\captionof{table}{Constraint tightening in direct method. \label{tab:robust-direct-tightening}}
\begin{tabular}{ r|c|c|c|c|c }
    Noise bound $\barvareps$ & 0.0001 & 0.0005 & 0.001 & 0.0015 & 0.002 \\
    \hline
    $a_{4, 19}$ & 7.411 & 418.66 & 5344.73 & 28486.42 & 99467.18 \\
\end{tabular}
\end{center}
}

As can be seen from \cref{tab:robust-direct-tightening}, the constraint tightening constant is large, and increases very quickly with the noise bound.
Remember that our output constraint is $\Yset = \left[-10, 10\right]$, so with a slightly larger noise bound, constraint \cref{eq:nominal-ddsf-output} will be trivially infeasible since $a_{4, 19} \geq 10$.
This is also the reason that we need to choose a very small noise bound $\barvareps = 0.0001$ in this example.

By applying an open-loop objective control input of a sine wave with amplitude $3$, we observe the closed-loop input and output as shown in \cref{fig:robust-direct-unwanted-interference}.

\includefig{robust-direct-unwanted-interference.pdf}{0.98}{Closed-loop input and output with direct method and safe objective input.}{fig:robust-direct-unwanted-interference}

As can be seen from \cref{fig:robust-direct-unwanted-interference}, the closed-loop input differs slightly from the objective input, even if the objective input is safe.

This is due to the coupling of regularizing term $\lamalpha \barvareps \twonorm{\alpha}^2$ in the objective function \cref{eq:nominal-ddsf-cost} and the dynamic constraint \cref{eq:robust-ddsf-direct-dynamic}.
As can be seen from \cref{eq:robust-ddsf-direct-dynamic}, with smaller $\alpha$, the input candidate sequence $\subseq{\baru}{0}{n-1}$ will also be smaller.
The regularizing term tries to make $\alpha$ smaller and make the candidate input $\subseq{\baru}{0}{n-1}$ smaller, in order to get a smaller overall cost, even if the objective input is safe.
This is unwanted input interference.


\section{Indirect Formulation}\label{sec:indirect-formulation}

To overcome the limitations of the direct formulation, we introduce the indirect formulation of the robust data-driven safety filter, with a qualitative constraint tightening scheme.

Firstly, to deal with the conservativeness, we introduce a new constraint tightening scheme, which makes the constraint tightening constants hyperparameters that we can choose.
Intuitively, since we only have qualitative guarantees for recursive feasibility and closed-loop stability, it is not necessary to have a rigorous but conservative constraint tightening scheme, as used in the constraint \cref{eq:robust-ddsf-direct-output}.

Secondly, we take advantage of the \emph{indirect method} \cite{dorflerBridgingDirectIndirect2023} to decompose the cost of safety filter and the dynamic constraint.

With these modifications, the indirect formulation of the robust data-driven safety filter can be formulated as:
\begin{subequations}
\label{eq:robust-ddsf-indirect}
\begin{align}
    \min_{\substack{\sigma \\ \bar{u}, \bar{y}}} \quad & \norm{\subseq{\baru}{0}{n-1} - \subseq{\uObj}{0}{n-1}(t)}_{\subseq{R}{0}{n-1}}^2 + \lambda_\sigma \norm{\sigma}_2^2 \label{eq:robust-ddsf-indirect-cost} \\
    \textrm{s.t.} \quad & 
    \subseq{\bary}{0}{L-1} + \sigma 
    = \hankel{L}{\subseq{\tildey^d}{l}{N-1}} 
    \begin{bmatrix}
        \hankel{L+l}{u^d} \\
        \hankel{l}{\subseq{\tildey^d}{0}{N-L-1}} \\
    \end{bmatrix}^{\dagger}
    \begin{bmatrix}
        \subseq{\baru}{-l}{L-1} \\
        \subseq{\bary}{-l}{-1} \\
    \end{bmatrix} \label{eq:robust-ddsf-indirect-dynamic} \\
    & 
    \begin{bmatrix}
        \subseq{\baru}{-l}{-1} \\
        \subseq{\bary}{-l}{-1} \\
    \end{bmatrix} = 
    \begin{bmatrix}
        \subseq{u}{t-l}{t-1} \\
        \subseq{\tildey}{t-l}{t-1} \\
    \end{bmatrix} \label{eq:robust-ddsf-indirect-initial} \\
    & 
    \begin{bmatrix}
        \subseq{\baru}{L-n}{L-1} \\
        \subseq{\bary}{L-n}{L-1} \\
    \end{bmatrix} = 
    \begin{bmatrix}
        \vRepeatVec{\us}{n} \\
        \vRepeatVec{\ys}{n} \\
    \end{bmatrix} \label{eq:robust-ddsf-indirect-terminal} \\
    &
    \bar{u}_k \in \Uset, \quad k \in \listinI{0}{L-1} \label{eq:robust-ddsf-indirect-input} \\
    &
    \norm{\bar{y}_k}_\infty + a_k \leq y_{\max}, \quad k \in \listinI{0}{L-1} \label{eq:robust-ddsf-indirect-output} \\
    &
   \norm{\sigma}_\infty \leq \bar{\varepsilon}\left( \left(1+\rho_{L}^{\max}\right)\norm{\alpha}_1 + \rho_{L}^{\max} \right) \textperiod \label{eq:robust-ddsf-indirect-sigma}
\end{align}
\end{subequations}
where $\rhoLmax$ is a constant of the system, as defined in (7) and discussion after (12) in \cite{berberichRobustConstraintSatisfaction2020}.
And we have the following definition of $\alpha$ and constraint tightening constants $a_k$:
\begin{align}
    \alpha &= \hankel{L+l}{\subseq{\tildey^d}{l}{N-1}} 
    \begin{bmatrix}
        \hankel{L+l}{u^d} \\
        \hankel{l}{\subseq{\tildey^d}{0}{N-L-1}} \\
    \end{bmatrix}^{\dagger}
    \begin{bmatrix}
        \subseq{\baru}{-l}{L-1} \\
        \subseq{\bary}{-l}{-1} \\
    \end{bmatrix} \textperiod \label{eq:robust-ddsf-indirect-alpha} \\
    a_k &= \sum_{i=1}^{\ceil{\frac{k+1}{n}}} c_i \textperiod \label{eq:robust-ddsf-indirect-ak}
\end{align}
where $\sequence{c}{k}{1}{\ceil{\frac{L}{n}}}$ is a sequence of positive constants that we can choose as hyperparameters.
Note that $\alpha$ is not an optimization variable, it's only an auxiliary variable used to construct constraint \cref{eq:robust-ddsf-indirect-sigma}.

Intuitively, we are tightening the output constraint by a constant $a_k$ at each time step, and the constant $a_k$ increases by a positive constant $c_i$ every $n$ time steps.
In other words, the constraint becomes more tight every $n$ time steps.

The dynamic constraint \cref{eq:robust-ddsf-indirect-dynamic} is formulated using the indirect method, as discussed in \cite{dorflerBridgingDirectIndirect2023}.
The pseudo inverse is introduced by the closed form solution of an inner optimization problem.
Detailed discussion and extensions of this method are given in \cref{sec:weighting-method}.
Due to the formulation, $\alpha$ is not an optimization variable anymore.
The cost \cref{eq:robust-ddsf-indirect-cost} if formulated similar to the cost in direct formulation \cref{eq:robust-ddsf-indirect-cost}, with the only difference that we do not have a regularizer term for $\alpha$.

The initial constraint \cref{eq:robust-ddsf-indirect-initial} only uses $l$ pairs of input-output, instead of $n$ pairs as in the direct formulation.
This is needed to provide qualitative guarantees, and requires some knowledge about the system.
In practice, this number can be chosen by trial and error.

Since we are using an indirect method, $\sigma$ only contains $\sequence{\sigma}{k}{0}{L-1}$, corresponding to the output prediction.
This affects our construction of candidate solution in the proof of \cref{thm:robust-ddsf-indirect}, as a result the constraint \cref{eq:robust-ddsf-indirect-sigma} is different from \cref{eq:robust-ddsf-direct-sigma}.
But the intuition of \cref{eq:robust-ddsf-indirect-sigma} is the same as \cref{eq:robust-ddsf-direct-sigma}: we need to render an upper-bound on $\sigma$.
\Cref{eq:robust-ddsf-indirect-sigma} is also non-convex, will be omitted in the implementation, and can be satisfied in practice by choosing $\lamsigma$ properly.

In order to provide qualitative guarantees, we need further assumptions on the system.

\begin{assumption}\label{asm:l-times-p-is-n}
    For the LTI system, we have $n=l \times p$.
\end{assumption}

\Cref{asm:l-times-p-is-n} is automatically satisfied for SISO systems and for systems that we can directly observe the state.
It seems quite restrictive, but in practice, even when this assumption is not satisfied, the formulation \cref{eq:robust-ddsf-indirect} can still perform well, as will be illustrated in \cref{subsec:numerical-example-indirect}.

And we require bounded input and output constraint sets.

\begin{assumption}\label{asm:bounded-input-output}
    The input and output constraint sets $\Uset$ and $\Yset$ are bounded.
\end{assumption}

We can prove that the formulation \cref{eq:robust-ddsf-indirect} can also provide qualitative guarantees for the system, but with slightly different assumptions from the direct formulation stated in \cref{thm:robust-ddsf-direct}.

\begin{theorem}[Qualitative guarantees for indirect formulation]\label{thm:robust-ddsf-indirect}
    Consider a controllable LTI system with bounded output noise, along with n-step receding horizon scheme.
    And suppose \cref{asm:dataset-L-2n-rich,asm:horizon-2-n,asm:equilibrium-interior,asm:l-times-p-is-n,asm:bounded-input-output} are satisfied.
    Then, for a certain choice of constraint tightening constants $\sequence{c}{k}{1}{\ceil{\frac{L}{n}}}$, there exists a constant $\varepsmax$, that makes following statement true:
    when the noise bound satisfies $\barvareps \leq \varepsmax$, recursive feasibility and closed-loop constraint satisfaction can be guaranteed for the formulation \cref{eq:robust-ddsf-indirect}.
\end{theorem}

We leave the proof of \cref{thm:robust-ddsf-indirect} to \cref{apps:prf-roubust-indirect}.

Note that we drop \cref{asm:objective-input-bound}, which says the deviation of candidate input from objective input is bounded.

\subsection{Numerical Example for Indirect Formulation}\label{subsec:numerical-example-indirect}

We use the same system as in \cref{subsec:numerical-example-direct}, to illustrate the effectiveness of the indirect formulation \cref{eq:robust-ddsf-indirect}.

First we use exactly the same setup as in \cref{subsec:numerical-example-direct}, and we choose the constraint tightening constants $c_i$ to be: $c_1 = 0.5$, $c_i = 0.1$ for $i \geq 2$.

The closed-loop input and output are shown in \cref{fig:robust-indirect-nonconservative} and \cref{fig:robust-indirect-no-interference}.

\includefig{robust-indirect-nonconservative.pdf}{0.98}{Closed-loop input and output with indirect method and unsafe objective input.}{fig:robust-indirect-nonconservative}

\includefig{robust-indirect-no-interference.pdf}{0.98}{Closed-loop input and output with indirect method and safe objective input.}{fig:robust-indirect-no-interference}

It can be seen in \cref{fig:robust-indirect-nonconservative} that, the constraint tightening scheme is not conservative anymore, as the closed-loop input and output are close to the constraint limit.
And in \cref{fig:robust-indirect-no-interference}, the closed-loop input is the same as the objective input, which is the desired behavior.

Then we change the noise bound to $\barvareps = 0.5$, in order to illustrate the effectiveness of formulation \cref{eq:robust-ddsf-indirect} under larger noise bound.
Note that the direct formulation \cref{eq:robust-ddsf-direct} will be trivially infeasible with this noise bound, since $a_{4, 19} \geq 10$.

If we use the same constraint tightening constants $c_i$ as before, the closed-loop input and output are shown in \cref{fig:robust-indirect-violation}.
The output constraint is violated, due to prediction error and not large enough constraint tightening constants.

\includefig{robust-indirect-violation.pdf}{0.98}{Closed-loop input and output with indirect method and too small tightening constant.}{fig:robust-indirect-violation}

We can choose another set of constraint tightening constants $c_i$: $c_1 = 1.5$, $c_i = 0.2$ for $i \geq 2$.
We can see from \cref{fig:robust-indirect-noviolation} that the output constraint is satisfied, and the closed-loop input and output are close to the constraint limit.

\includefig{robust-indirect-noviolation.pdf}{0.98}{Closed-loop input and output with indirect method and proper tightening constant.}{fig:robust-indirect-noviolation}

\newpage
Next, we change the system into a system with two outputs, to illustrate that the formulation \cref{eq:robust-ddsf-indirect} can also work even if the assumption $n=l \times p$ is not satisfied.

For this purpose, we write the system into a state space model:
\begin{align*}
    A = \begin{bmatrix}
        2.1 & -1.5 & 0.3 \\
        1 & 0 & 0 \\
        0 & 1 & 0 \\
    \end{bmatrix}, \quad
    B = \begin{bmatrix}
        1 \\
        0 \\
        0 \\
    \end{bmatrix}, \quad
    C = 0.01 \begin{bmatrix}
        2 & 6.1 & 1.1 \\
        0 & 10 & 0 \\
    \end{bmatrix}, \quad
    D = \begin{bmatrix}
        0 \\
        0 \\
    \end{bmatrix} \textstop
\end{align*}

Note that in this case, $n=3$, $l=2$, $p=2$ and $m=1$.
The first output is the same as the output of the original system, and the second output is not constrained.
We also need to modify the constraint tightening constants to be: $c_1 = 1.7$, $c_i = 0.1$ for $i \geq 2$.

We can see from \cref{fig:robust-indirect-simo} that the closed-loop input and output are close to the constraint limit, and the output constraint is satisfied.

\includefig{robust-indirect-simo.pdf}{0.98}{Closed-loop input and first output with indirect method, on system with two outputs.}{fig:robust-indirect-simo}

The problem of how to choose the constraint tightening constants properly is left for future research.
In practice, we can always start from a conservative constraint tightening scheme, and then gradually decrease the tightening until the input interference is small enough and the constraints are still satisfied.

Also, it's worth noticing that the number of optimization variables in the indirect formulation \cref{eq:robust-ddsf-indirect} has nothing to do with the size of dataset trajectory, and is only related to the prediction horizon $L$.
This is a big advantage of the indirect formulation, since it makes the problem scalable to large dataset.
Also, due to less optimization variables, the indirect formulation is usually faster to solve than the direct formulation.
In the example above, the direct formulation takes about $0.79$ seconds to solve, while the indirect formulation only takes about $0.08$ seconds to solve.
